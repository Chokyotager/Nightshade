{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import data as dat\n",
    "from model import Model\n",
    "\n",
    "import colours as c\n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "dir = os.getcwd()\n",
    "dir_main = os.path.dirname(os.path.abspath(dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = dat.Scorer()\n",
    "m = Model(scorer.smiles_vocabulary, dropout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceTemplate (template, replace, figure):\n",
    "    bio = BytesIO()\n",
    "\n",
    "    figure.savefig(bio, format=\"png\")\n",
    "\n",
    "    image = base64.encodebytes(bio.getvalue()).decode()\n",
    "    return template.replace(replace, \"<img class=\\\"plot\\\" src=\\\"data:image/png;base64,{}\\\"/> \".format(image))\n",
    "\n",
    "template = open(dir_main + \"/report/template.html\").read()\n",
    "\n",
    "model_name = \"Solanaceae-N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(session, dir_main + \"/trained/\" + model_name)\n",
    "    \n",
    "    iteration = session.run(m.global_step)\n",
    "    \n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    # Score the data iteratively\n",
    "    smiles, labels, weights, smiles_raw = scorer.getEvaluations()\n",
    "    \n",
    "    total = [0] * scorer.classes_amount\n",
    "    \n",
    "    # Classifications\n",
    "    false_negative = [0] * scorer.classes_amount\n",
    "    false_positive = [0] * scorer.classes_amount\n",
    "    \n",
    "    true_negative = [0] * scorer.classes_amount\n",
    "    true_positive = [0] * scorer.classes_amount\n",
    "    \n",
    "    outputs = list()\n",
    "    weight_list = list()\n",
    "    \n",
    "    for smile, label, weight, smile_raw in zip(smiles, labels, weights, smiles_raw):\n",
    "        \n",
    "        output = session.run([m.output], feed_dict={m.batch_size: 1, m.input: np.expand_dims(smile, 0)})\n",
    "        \n",
    "        outputs.append(output[0])\n",
    "        output = list(np.round(output)[0,0])\n",
    "        \n",
    "        weight_list.append(weights[0])\n",
    "\n",
    "        \n",
    "        for i in range(len(label)):\n",
    "            \n",
    "            if label[i] != 0.5:\n",
    "                \n",
    "                total[i] += 1\n",
    "            \n",
    "                if label[i] == output[i]:\n",
    "\n",
    "                    if output[i] == 1:\n",
    "                        true_positive[i] += 1\n",
    "\n",
    "                    elif output[i] == 0:\n",
    "                        true_negative[i] += 1\n",
    "\n",
    "                elif label[i] != output[i]:\n",
    "\n",
    "                    if output[i] == 1:\n",
    "                        false_positive[i] += 1\n",
    "\n",
    "                    elif output[i] == 0:\n",
    "                        false_negative[i] += 1\n",
    "                \n",
    "        print(\"Total: {}\".format(total))\n",
    "    \n",
    "    true_positive, true_negative, false_positive, false_negative, total = np.array(true_positive), np.array(true_negative), np.array(false_positive), np.array(false_negative), np.array(total)\n",
    "    #[88.17733990147784, 97.77777777777777, 98.62306368330465, 92.61363636363636, 89.53488372093024, 96.661101836394, 94.70198675496688, 82.67148014440433, 93.88083735909822, 96.55172413793103, 88.95027624309392, 93.4959349593496]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate graphs\n",
    "figure = plt.figure(figsize=(18, 9))\n",
    "    \n",
    "tp_per = true_positive/total * 100\n",
    "tn_per = true_negative/total * 100\n",
    "\n",
    "fp_per = false_positive/total * 100\n",
    "fn_per = false_negative/total * 100\n",
    "\n",
    "# Compoutes the FP/TP rates at standard cutoff\n",
    "fp_rate = false_positive/(false_positive + true_negative)\n",
    "tp_rate = true_positive/(true_positive + false_negative)\n",
    "    \n",
    "one = plt.barh(scorer.classes, tn_per + tp_per, color=\"red\")\n",
    "two = plt.barh(scorer.classes, tp_per, color=\"blue\")\n",
    "plt.legend([one, two], [\"True negative\", \"True positive\"], loc=4)\n",
    "\n",
    "for i, v in enumerate(tn_per + tp_per):\n",
    "    plt.text(v, i - .1, str(round(v*100)/100), color=\"red\", fontweight=\"bold\")\n",
    "    \n",
    "for i, v in enumerate(tp_per):\n",
    "    plt.text(v, i - .1, str(round(v*100)/100), color=\"blue\", fontweight=\"bold\")\n",
    "\n",
    "plt.xlabel(\"Percentage [numbers rounded] / %\")\n",
    "plt.title(\"Correct predictions\", fontweight=\"bold\")\n",
    "\n",
    "template = replaceTemplate(template, \"{correct_graph}\", figure)\n",
    "    \n",
    "figure = plt.figure(figsize=(18, 9))\n",
    "one = plt.barh(scorer.classes, fn_per + fp_per, color=\"green\")\n",
    "two = plt.barh(scorer.classes, fp_per, color=\"yellow\")\n",
    "\n",
    "for i, v in enumerate(fn_per + fp_per):\n",
    "    plt.text(v + .1, i - .1, str(round(v*100)/100), color=\"green\", fontweight=\"bold\")\n",
    "    \n",
    "for i, v in enumerate(fp_per):\n",
    "    plt.text(v + .1, i - .1, str(round(v*100)/100), color=\"yellow\", fontweight=\"bold\")\n",
    "\n",
    "plt.legend([one, two], [\"False negative\", \"False positive\"], loc=4)\n",
    "plt.xlabel(\"Percentage [numbers rounded] / %\")\n",
    "plt.title(\"Incorrect predictions\", fontweight=\"bold\")\n",
    "\n",
    "template = replaceTemplate(template, \"{wrong_graph}\", figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swap_labels = np.swapaxes(labels, 0, 1)\n",
    "swap_outs = np.swapaxes(np.squeeze(outputs), 0, 1)\n",
    "\n",
    "# Weight scores are already computed up to this point, there is no need for further integration\n",
    "swap_weights = np.swapaxes(np.squeeze(weight_list), 0, 1)\n",
    "\n",
    "def createRoc (index, figure):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true=np.floor(swap_labels[index]), y_score=swap_outs[index], pos_label=1)\n",
    "    #fpr, tpr, thresholds = metrics.roc_curve(y_true=np.floor(swap_labels[index]), y_score=swap_outs[index], pos_label=1)\n",
    "    auc_score = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    figure.add_subplot(6, 2, (index + 1))\n",
    "\n",
    "    one = plt.plot(fpr, tpr, color=\"blue\")\n",
    "    two = plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylim(0, 1.03)\n",
    "    plt.xlim(0, 1)\n",
    "\n",
    "    plt.legend(one, [\"Area under curve = {}\".format(auc_score)], loc=4)\n",
    "\n",
    "    plt.title(\"ROC curve for {}\".format(scorer.classes[index]), fontweight=\"bold\")\n",
    "    \n",
    "    return auc_score\n",
    "    \n",
    "auc_scores = list()\n",
    "\n",
    "figure = plt.figure(figsize=(20, 20*3))\n",
    "\n",
    "for i in range(scorer.classes_amount):\n",
    "    auc_scores.append(createRoc(i, figure))\n",
    "    \n",
    "plt.show()\n",
    "template = replaceTemplate(template, \"{roc_metric}\", figure)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = template.replace(\"{model_name}\", model_name)\n",
    "\n",
    "from time import gmtime, strftime\n",
    "template = template.replace(\"{time}\", strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()) + \" UTC\")\n",
    "template = template.replace(\"{iterations_trained}\", str(iteration))\n",
    "\n",
    "template = template.replace(\"{compounds_tested}\", str(scorer.smiles_length))\n",
    "\n",
    "# fill values\n",
    "\"\"\"\n",
    "      <tr>\n",
    "        <th>AhR</th>\n",
    "        <th>{ahr_accounted}</th>\n",
    "        <th>&nbsp</th>\n",
    "        <th>{ahr_auc}</th>\n",
    "        <th>&nbsp</th>\n",
    "        <th>{ahr_accuracy}</th>\n",
    "        <th>{ahr_precision}</th>\n",
    "        <th>{ahr_fdr}</th>\n",
    "        <th>{ahr_for}</th>\n",
    "      </tr>\n",
    "\"\"\"\n",
    "\n",
    "trex = str()\n",
    "\n",
    "def sf4 (x):\n",
    "    return round(x * 1000)/1000\n",
    "\n",
    "for i in range(len(scorer.classes)):\n",
    "        trex += \"<tr><th>{}</th><th>{}</th><th>{}</th><th>&nbsp</th><th>{}\\\n",
    "        </th><th>&nbsp</th><th>{}</th><th>{}</th>\\\n",
    "        <th>{}</th><th>{}</th></tr>\".format(scorer.classes[i],\n",
    "                                            total[i],\n",
    "                                            false_negative[i] + true_positive[i],\n",
    "                                            sf4(auc_scores[i]), \n",
    "                                            sf4((true_positive[i] + true_negative[i])/total[i]), \n",
    "                                            sf4(true_positive[i]/(true_positive[i] + false_negative[i])), \n",
    "                                            sf4(false_positive[i]/(false_positive[i] + true_positive[i])),\n",
    "                                            sf4(false_negative[i]/(false_negative[i] + true_negative[i])))\n",
    "        \n",
    "template = template.replace(\"{table1_values}\", trex)\n",
    "       \n",
    "open(dir_main + \"/report/report.html\", \"w+\").write(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_positive + false_negative + true_negative + false_positive)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles, labels, weights, smiles_raw = scorer.getEvaluations()\n",
    "\n",
    "accounts = [0] * scorer.classes_amount\n",
    "\n",
    "for label in labels:\n",
    "    \n",
    "    for i in range(scorer.classes_amount):\n",
    "        \n",
    "        if label[i] == 1:\n",
    "            accounts[i] += 1\n",
    "            \n",
    "print(accounts)\n",
    "print(total)\n",
    "\n",
    "print(false_negative + true_positive)\n",
    "\n",
    "print(scorer.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
